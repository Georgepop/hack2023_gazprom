{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f3470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "\n",
    "import datetime\n",
    "import platform\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def flat(ll):\n",
    "    return list(itertools.chain(*ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e654a76",
   "metadata": {},
   "source": [
    "Основной класс, который образует маршруты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0db5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Worker:\n",
    "\n",
    "    def vrp(self):\n",
    "\n",
    "        location_all = pd.concat([self.dep2] + [self.location],\n",
    "                                 axis=0)\n",
    "\n",
    "        # ограничиваем матрицу расстояний до нужных пределов\n",
    "        dd_matrix = self.d_matrix.loc[location_all.index, location_all.index]\n",
    "\n",
    "        ###########################\n",
    "        # Problem Data Definition #\n",
    "        ###########################\n",
    "        def create_data_model():\n",
    "            \"\"\"Stores the data for the problem\"\"\"\n",
    "            data = {}\n",
    "\n",
    "            data['distance_matrix'] = dd_matrix.astype(int).values.tolist()\n",
    "            data['demands'] = list(location_all.loc[:, 'volume'].astype(int))\n",
    "            data['must'] = list(location_all.loc[:, 'must'].astype(int))\n",
    "\n",
    "            data['num_locations'] = len(data['demands'])\n",
    "            data['time_per_demand_unit'] = list(\n",
    "                location_all.loc[:, 'time_spent'].astype(int))\n",
    "            data['time_windows'] = [(int(i), int(k)) for i, k in\n",
    "                                    zip(location_all['time_from'], location_all['time_to'])]\n",
    "            data['num_vehicles'] = self.num_vehic\n",
    "            data['vehicle_capacity'] = self.vehicle_capacity\n",
    "            data['depot'] = 0\n",
    "            return data\n",
    "\n",
    "        #######################\n",
    "        # Problem Constraints #\n",
    "        #######################\n",
    "\n",
    "        def create_distance_evaluator(data):\n",
    "            \"\"\"Creates callback to return distance between points.\"\"\"\n",
    "            _distances = data['distance_matrix']\n",
    "\n",
    "            def distance_evaluator(manager, from_node, to_node):\n",
    "                \"\"\"Returns the manhattan distance between the two nodes\"\"\"\n",
    "                return _distances[manager.IndexToNode(from_node)][manager.IndexToNode(to_node)]\n",
    "            # - data['demands'][manager.IndexToNode(from_node)]\n",
    "            #\n",
    "\n",
    "            return distance_evaluator\n",
    "\n",
    "        def create_demand_evaluator(data):\n",
    "\n",
    "            def demand_evaluator(manager, from_node):\n",
    "                return data['demands'][manager.IndexToNode(from_node)]\n",
    "\n",
    "            return demand_evaluator\n",
    "\n",
    "        def add_capacity_constraints(routing, manager, data, demand_evaluator_index):\n",
    "            capacity = 'Capacity'\n",
    "            routing.AddDimension(\n",
    "                demand_evaluator_index,\n",
    "                0,  # null capacity slack\n",
    "                data['vehicle_capacity'],  # vehicle maximum capacities\n",
    "                True,  # start cumul to zero\n",
    "                'Capacity')\n",
    "\n",
    "            list_add_junc1 = []\n",
    "            list_add_junc2 = []\n",
    "            for node in range(1, len(data['demands'])):\n",
    "                if data['must'][node] == 1:\n",
    "                    list_add_junc1 += [node]\n",
    "                elif data['must'][node] == 2:\n",
    "                    list_add_junc2 += [node]\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            for node in list_add_junc1:\n",
    "                routing.AddDisjunction([manager.NodeToIndex(node)], 1000_0000)\n",
    "\n",
    "            for node in list_add_junc2:\n",
    "                routing.AddDisjunction([manager.NodeToIndex(node)], 1000)\n",
    "\n",
    "        def create_time_evaluator(data):\n",
    "            \"\"\"Creates callback to get total times between locations.\"\"\"\n",
    "\n",
    "            def service_time(data, node):\n",
    "                \"\"\"Gets the service time for the specified location.\"\"\"\n",
    "                return abs(data['time_per_demand_unit'][node])\n",
    "\n",
    "            def travel_time(data, from_node, to_node):\n",
    "                \"\"\"Gets the travel times between two locations.\"\"\"\n",
    "                if from_node == to_node:\n",
    "                    travel_time = 0\n",
    "                else:\n",
    "                    travel_time = int(\n",
    "                        data['distance_matrix'][from_node][to_node])\n",
    "                return travel_time\n",
    "\n",
    "            _total_time = {}\n",
    "            # precompute total time to have time callback in O(1)\n",
    "            for from_node in range(data['num_locations']):\n",
    "                _total_time[from_node] = {}\n",
    "                for to_node in range(data['num_locations']):\n",
    "                    if from_node == to_node:\n",
    "                        _total_time[from_node][to_node] = 0\n",
    "                    else:\n",
    "                        _total_time[from_node][to_node] = int(\n",
    "                            service_time(data, from_node) + travel_time(\n",
    "                                data, from_node, to_node))\n",
    "\n",
    "            def time_evaluator(manager, from_node, to_node):\n",
    "                \"\"\"Returns the total time between the two nodes\"\"\"\n",
    "                return _total_time[manager.IndexToNode(from_node)][manager.IndexToNode(\n",
    "                    to_node)]\n",
    "\n",
    "            return time_evaluator\n",
    "\n",
    "        def add_time_window_constraints(routing, manager, data, time_evaluator):\n",
    "            \"\"\"Add Time windows constraint\"\"\"\n",
    "            time = 'Time'\n",
    "            routing.AddDimension(\n",
    "                time_evaluator,\n",
    "                2000,  # allow waiting time\n",
    "                1600,  # maximum time per vehicle\n",
    "                False,  # don't force start cumul to zero since we are giving TW to start nodes\n",
    "                time)\n",
    "            time_dimension = routing.GetDimensionOrDie(time)\n",
    "            # Add time window constraints for each location except depot\n",
    "            # and 'copy' the slack var in the solution object (aka Assignment) to print it\n",
    "            for location_idx, time_window in enumerate(data['time_windows']):\n",
    "                if location_idx in [0]:\n",
    "                    continue\n",
    "                index = manager.NodeToIndex(location_idx)\n",
    "                time_dimension.CumulVar(index).SetRange(\n",
    "                    time_window[0], time_window[1])\n",
    "                routing.AddToAssignment(time_dimension.SlackVar(index))\n",
    "            # Add time window constraints for each vehicle start node\n",
    "            # and 'copy' the slack var in the solution object (aka Assignment) to print it\n",
    "\n",
    "            from_n = [self.start_time_veh]*data['num_vehicles']\n",
    "            to_n = [self.end_time_veh]*data['num_vehicles']\n",
    "\n",
    "            for vehicle_id in range(data['num_vehicles']):\n",
    "                index = routing.Start(vehicle_id)\n",
    "                time_dimension.CumulVar(index).SetRange(int(from_n[vehicle_id]),\n",
    "                                                        int(to_n[vehicle_id]))\n",
    "\n",
    "                routing.AddToAssignment(time_dimension.SlackVar(index))\n",
    "\n",
    "                index = routing.End(vehicle_id)\n",
    "                time_dimension.CumulVar(index).SetRange(int(from_n[vehicle_id]),\n",
    "                                                        int(to_n[vehicle_id]))\n",
    "\n",
    "        def print_solution(data, manager, routing, assignment):\n",
    "\n",
    "            time_dimension = routing.GetDimensionOrDie('Time')\n",
    "\n",
    "            route = []\n",
    "\n",
    "            for vehicle_id in range(data['num_vehicles']):\n",
    "\n",
    "                index = routing.Start(vehicle_id)\n",
    "                route_time = []\n",
    "                route_volume = []\n",
    "                output = []\n",
    "                route_money = []\n",
    "\n",
    "                while not routing.IsEnd(index):\n",
    "\n",
    "                    node_index = manager.IndexToNode(index)\n",
    "\n",
    "                    route_volume += [data['demands'][node_index]]\n",
    "\n",
    "                    time_var = time_dimension.CumulVar(index)\n",
    "                    route_time += [(assignment.Min(time_var),\n",
    "                                    assignment.Max(time_var))]\n",
    "\n",
    "                    previous_index = index\n",
    "\n",
    "                    index = assignment.Value(routing.NextVar(index))\n",
    "\n",
    "                    if index != -1:  # routing.Start(vehicle_id):\n",
    "                        route_money += [routing.GetArcCostForVehicle(\n",
    "                            previous_index, index, vehicle_id)]\n",
    "\n",
    "                        # dist_var = distance_dimension.CumulVar(index)\n",
    "                        # route_dist += [assignment.Value(dist_var)]\n",
    "\n",
    "                    output += [node_index]\n",
    "\n",
    "                node_index = manager.IndexToNode(index)\n",
    "\n",
    "                route_volume += [data['demands'][node_index]]\n",
    "\n",
    "                time_var = time_dimension.CumulVar(index)\n",
    "                route_time += [(assignment.Min(time_var),\n",
    "                                assignment.Max(time_var))]\n",
    "\n",
    "                output += [node_index]\n",
    "\n",
    "                if len(output) > 2:\n",
    "\n",
    "                    rinfo = {'uid': location_all.iloc[output].index.tolist(),\n",
    "                             'dist': [0] + [int(i) for i in route_money]\n",
    "                             }\n",
    "                    rinfo['must'] = location_all['must'].iloc[output].tolist()\n",
    "\n",
    "                    rinfo['time'] = [j[0] for j in route_time]\n",
    "\n",
    "                    rinfo['volume'] = route_volume[:-1] + [0]\n",
    "\n",
    "                    rinfo['dist'] += [\n",
    "                        create_distance_evaluator(data)(manager, 1, 0)]\n",
    "                    rinfo['time'] += [rinfo['time'][-1] +\n",
    "                                      create_time_evaluator(data)(manager, 1, 0)]\n",
    "\n",
    "                    route += [rinfo]\n",
    "\n",
    "            return route\n",
    "\n",
    "        \"\"\"Entry point of the program\"\"\"\n",
    "        # Instantiate the data problem.\n",
    "        data = create_data_model()\n",
    "\n",
    "        # Create the routing index manager\n",
    "        manager = pywrapcp.RoutingIndexManager(\n",
    "            len(data['distance_matrix']), data['num_vehicles'], 0)\n",
    "\n",
    "        # Create Routing Model\n",
    "        routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "        # Define weight of each edge\n",
    "        distance_evaluator_index = routing.RegisterTransitCallback(\n",
    "            partial(create_distance_evaluator(data), manager))\n",
    "        routing.SetArcCostEvaluatorOfAllVehicles(distance_evaluator_index)\n",
    "\n",
    "        # routing.SetFixedCostOfAllVehicles(self.fixed)\n",
    "\n",
    "        # Add Capacity constraint\n",
    "        demand_evaluator_index = routing.RegisterUnaryTransitCallback(\n",
    "            partial(create_demand_evaluator(data), manager))\n",
    "        add_capacity_constraints(\n",
    "            routing, manager, data, demand_evaluator_index)\n",
    "\n",
    "        # Add Time Window constraint\n",
    "        time_evaluator_index = routing.RegisterTransitCallback(\n",
    "            partial(create_time_evaluator(data), manager))\n",
    "        add_time_window_constraints(\n",
    "            routing, manager, data, time_evaluator_index)\n",
    "\n",
    "        # Setting first solution heuristic (cheapest addition).\n",
    "        search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "        search_parameters.first_solution_strategy = (\n",
    "            routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "\n",
    "        if platform.system() == 'Windows':\n",
    "            search_parameters.log_search = True\n",
    "\n",
    "        # Solve the problem.\n",
    "        st = time.time()\n",
    "        solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "        if solution:\n",
    "            route = print_solution(data, manager, routing, solution)\n",
    "        else:\n",
    "            print(\"No solution found !\")\n",
    "\n",
    "        ptime = time.time() - st\n",
    "        print(ptime)\n",
    "        print(len(route))\n",
    "        print('dist', [max(i['time']) for i in route])\n",
    "        print('dist', sum([sum(i['volume']) for i in route]))\n",
    "\n",
    "        return route\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1d2f0",
   "metadata": {},
   "source": [
    "Импорт всех таблиц, уменьшение размера чисел, матрица асстояний как матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b99e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "OptimusG = Worker()\n",
    "\n",
    "OptimusG.dep2 = pd.DataFrame([{'volume': 0, 'time_from': 480, 'time_to': 1200, 'time_spent': 0, 'must': 0}])\n",
    "\n",
    "OptimusG.start_time_veh = 480\n",
    "OptimusG.end_time_veh = 1200\n",
    "OptimusG.vehicle_capacity = 1000_000\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    d1 = pd.read_csv('C:/Users/User/Desktop/hac/times v4.csv')\n",
    "    table_incomes = pd.read_excel(\n",
    "        'C:/Users/User/Desktop/hac/terminal_data_hackathon v4.xlsx', sheet_name='Incomes').set_index('TID')\n",
    "else:\n",
    "    d1 = pd.read_csv('/root/times v4.csv')\n",
    "    table_incomes = pd.read_excel(\n",
    "        '/root/terminal_data_hackathon v4.xlsx', sheet_name='Incomes').set_index('TID')\n",
    "\n",
    "table_incomes['2022-12-01'] = 0\n",
    "table_incomes = (table_incomes/1000).astype(int)\n",
    "table_incomes['90%'] = table_incomes.iloc[:, 1:].apply(lambda x: np.percentile(x, 90), axis=1)\n",
    "table_incomes['25%'] = table_incomes.iloc[:, 1:-1].apply(lambda x: np.percentile(x, 25), axis=1)\n",
    "\n",
    "all_free_dive = table_incomes.loc[(table_incomes['90%'] < 150)|\n",
    "                                  (table_incomes['25%'] < 50)].index\n",
    "\n",
    "\n",
    "# формирование матрицы расстояний\n",
    "d1 = pd.pivot_table(d1, index='Origin_tid',\n",
    "                    columns='Destination_tid', values='Total_Time').fillna(0)\n",
    "d1 = pd.concat([pd.DataFrame([0]*len(d1), index=d1.index).T, d1], axis=0)\n",
    "d1[0] = 0\n",
    "OptimusG.d_matrix = np.round(d1[sorted(d1.columns)])\n",
    "\n",
    "\n",
    "# функция, которая поддает оптимальные точки подлизости\n",
    "def get_nearnodes(tam, takaa):\n",
    "    ta_ta = pd.DataFrame()\n",
    "    for i in tam:\n",
    "        tadam = OptimusG.d_matrix.loc[[i], takaa].T\n",
    "        tadam.columns = [0]\n",
    "        ta_ta = pd.concat([ta_ta, tadam], axis=0)\n",
    "    ta_ta = ta_ta.reset_index().groupby('index')[[0]].min().sort_values(0)\n",
    "    return [i for i in ta_ta.index if i not in tam]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c4871",
   "metadata": {},
   "source": [
    "Основной цикл, который перебирает во все дни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650df171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Count 0\n",
      "остаток на 31.08.2022 (входящий)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_11980/1355391931.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  loct['must'] = (loct[m] + loct['90%'] > 1000).astype(int)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    1530\n",
      "1      20\n",
      "Name: must, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "da_inc = pd.DataFrame()\n",
    "routes = []\n",
    "used = []\n",
    "for n in range(0, 92):\n",
    "\n",
    "    if n % 14 == 0:\n",
    "        used = []\n",
    "\n",
    "    print('\\n\\n Count', n)\n",
    "    m, n1 = table_incomes.columns[n], table_incomes.columns[n+1]\n",
    "    print(m)\n",
    "\n",
    "    loct = table_incomes[[m, '90%']]\n",
    "    loct['must'] = (loct[m] + loct['90%'] > 1000).astype(int)\n",
    "\n",
    "    little_bb_init = list(loct.loc[loct['must'] == 1].index)\n",
    "    little_m_have = list(set(all_free_dive) - set(used))\n",
    "\n",
    "    little_m_have = get_nearnodes(little_bb_init, little_m_have)\n",
    "\n",
    "    # те точки которые  необязательные мы обозначаем как:\n",
    "    loct['must'].loc[little_m_have[:]] = 2\n",
    "    loct = loct.loc[loct['must'] > 0]\n",
    "\n",
    "    print(loct['must'].value_counts())\n",
    "    loct = loct.rename(columns={m: 'volume'})\n",
    "    loct['time_from'] = 480\n",
    "    loct['time_to'] = 1200\n",
    "    loct['time_spent'] = 10\n",
    "\n",
    "    OptimusG.location = loct\n",
    "    OptimusG.num_vehic = 5\n",
    "    OptimusG.fixed = 1000_000\n",
    "    # сама функция рассчета маршрутов\n",
    "    route = OptimusG.vrp()\n",
    "\n",
    "    routes += [route]\n",
    "\n",
    "    sum_routes = flat([i['uid'] for i in route])\n",
    "    sum_routes = [i for i in sum_routes if i != 0]\n",
    "\n",
    "    print('Len sum_rout', len(sum_routes))\n",
    "    print('Must ', len(set(little_bb_init)-set(sum_routes)))\n",
    "\n",
    "    used += sum_routes\n",
    "\n",
    "    da_inc = pd.concat([da_inc,table_incomes[[m]]], axis=1)\n",
    "\n",
    "\n",
    "    # записываем в новый день\n",
    "    table_incomes[m].loc[sum_routes] = 0\n",
    "    table_incomes[n1] += table_incomes[m]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb354d22",
   "metadata": {},
   "source": [
    "Формирование отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# мой внутренний отчет\n",
    "da_inc.to_excel(f'/root/proverka_inc.xlsx')      \n",
    "\n",
    "# фаил остатков\n",
    "table_incomes.to_excel(f'/root/table_inc.xlsx')\n",
    "\n",
    "# маршрутов\n",
    "with open(f'/root/dahun_pao.json', 'w') as outfile:\n",
    "    json.dump(routes, outfile)\n",
    "\n",
    "# сдвигаем колонки в фаиле тк мы считали на день в день\n",
    "cols = [i.split(' ')[0] for i in table_incomes.columns[1:-1]]\n",
    "table_incomes = table_incomes.iloc[:, :-2]\n",
    "table_incomes.columns = cols\n",
    "table_incomes = (table_incomes*1000).astype(int)\n",
    "\n",
    "\n",
    "# \n",
    "d_start = pd.DataFrame()\n",
    "for k, route in enumerate(routes):\n",
    "    columns = ['uid', 'dist', 'time', 'volume', 'must']\n",
    "    d = pd.DataFrame(flat([[list(ii)+[k] for ii in zip(*[j[i] for i in columns])]\n",
    "                           for k, j in enumerate(route)]), columns=columns+['n'])\n",
    "    d['date'] = table_incomes.columns[k]\n",
    "    d_start = pd.concat([d_start, d], axis=0)\n",
    "\n",
    "d_start = d_start.rename(columns={'uid': 'TID'})\n",
    "d_start['was_taken'] = d_start['volume'].map(lambda x: x * 0.1 if x > 1_000 else 100)\n",
    "d_start.to_excel(f'/root/_.xlsx')\n",
    "\n",
    "\n",
    "incass_fond = table_incomes.applymap(lambda x: x*(2/100/365))\n",
    "\n",
    "# формирование фаила инкас издержек (+100)\n",
    "tabl_inc_reset = table_incomes.stack().reset_index().iloc[:, :2]\n",
    "tabl_inc_reset.columns = ['TID', 'date']\n",
    "table_ras = d_start[['TID', 'date', 'was_taken']].merge(tabl_inc_reset, on=['TID', 'date'], how='right')\n",
    "table_ras = pd.pivot_table(table_ras, index='TID', columns='date', values='was_taken')\n",
    "\n",
    "# формирование фаила итого\n",
    "itogo = pd.concat([pd.DataFrame(table_ras.sum()).T, pd.DataFrame(incass_fond.sum()).T,\n",
    "                   pd.DataFrame(incass_fond.sum()).T], axis=0)\n",
    "itogo.iloc[2] = 20000*5\n",
    "itogo = pd.concat([itogo, pd.DataFrame(itogo.sum()).T], axis=0)\n",
    "itogo.index = ['фондирование', 'инкассация',\n",
    "               'стоимость броневиков', 'итого']\n",
    "\n",
    "# формирование фаила маршрутов\n",
    "d_start = d_start.loc[d_start['TID'] != 0]\n",
    "d_start['дата-время прибытия'] = d_start.apply(lambda x: pd.to_datetime(x['date'])+datetime.timedelta(minutes=x['time']), axis=1)\n",
    "d_start['дата-время отъезда'] = d_start.apply(lambda x: pd.to_datetime(x['date'])+datetime.timedelta(minutes=x['time']+10), axis=1)\n",
    "d_start = d_start.rename(columns={'n': 'порядковый номер броневика',\n",
    "                                  'TID': 'устройство'}).set_index(['порядковый номер броневика', 'date'])\n",
    "d_start = d_start.drop(columns=['dist', 'volume', 'time', 'must', 'was_taken'])\n",
    "\n",
    "final_otch = [['остатки на конец дня', table_incomes],\n",
    "         ['стоимость фондирования', incass_fond],\n",
    "         ['стоимость инкассации', table_ras],\n",
    "         ['маршруты', d_start],\n",
    "         ['итог', itogo]]\n",
    "\n",
    "with pd.ExcelWriter(\"/root/отсчёт.xlsx\") as writer: \n",
    "    for i in final_otch:\n",
    "        i[1].to_excel(writer, sheet_name=i[0])\n",
    "\n",
    "\n",
    "table_ras = table_ras.applymap(lambda x: 1 if x > 0 else 0)\n",
    "row_686 = [k for k, i in enumerate(table_incomes.columns) if k % 14 == 0]\n",
    "\n",
    "for i in range(len(row_686)-1):\n",
    "    row_rae = list(table_ras.loc[table_ras.iloc[:, row_686[i]:row_686[i+1]].sum(axis=1) == 0].index)\n",
    "    if len(row_rae)>10:\n",
    "        print(row_686[i], row_686[i+1])\n",
    "    else:\n",
    "        print(row_686[i], row_686[i+1], row_rae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
